---
type: "quote"
author: "Sholto Douglas"
date: "2025-10-02"
url: "https://youtu.be/FQy4YMYFLsI?si=Ao-7mP1qft0l2s3d&t=1125"
tags: ["AI", "ML", "research"]
---

> Matt Turck: What does taste mean when it comes to AI research?
>
> Sholto Douglas: One of the most important things is mechanistically understanding exactly what you’re trying to do and having an implicit simplicity regularizer. When you think about taste in ML, it’s the crucial ingredient that allows you to decide what goes into your large training run when you have imperfect information.
>
> We can study very deeply what the impact of an architectural change is, but past a certain level of scale, you have to guess whether the impact of that change will compound with others or conflict. You can’t test your full-scale run multiple times — you often have only one shot.
>
> So a lot of taste comes from being able to make good inferences about whether something will deliver increasing returns to scale. It’s also about judging whether a research direction is worth pursuing. Our baselines in ML are often so well-tuned that it’s very hard to beat them, even with theoretically better methods, because so many small tricks are required to make a machine learning method work, and they can fail for any number of reasons.
>
> It’s not like building a bridge, where you have a good idea why a particular shear was introduced. There can be all these quirks, and knowing whether to keep pushing in a given direction or abandon it for another is another aspect of taste. It always comes back to simplicity as a guiding regularizer.
