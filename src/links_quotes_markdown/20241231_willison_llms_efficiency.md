---
type: "quote"
author: "Simon Willison"
date: "2024-12-31"
url: "https://simonwillison.net/2024/Dec/31/llms-in-2024/"
tags: ["LLMs"]
---

> The efficiency thing is really important for everyone who is concerned about the environmental impact of LLMs. These price drops tie directly to how much energy is being used for running prompts. There's still plenty to worry about with respect to the environmental impact of the great AI datacenter buildout, but a lot of the concerns over the energy cost of individual prompts are no longer credible.