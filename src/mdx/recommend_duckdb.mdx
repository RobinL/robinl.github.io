---
title: "Why DuckDB is my first choice for data processing"
description: ""
post_date: "2025-03-16"
post_category: "data"
code_url: "https://github.com/RobinL/robinl.github.io/blob/dev/src/mdx/recommend_duckdb.mdx"
---

export { MDXLayout as default } from '../components/MDXLayout';
import { SEO } from "../components/SEO"
export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;
import { Link } from "gatsby";

# Why DuckDB is my first choice for data processing

Over the past few years, I've found myself using DuckDB more and more for data processing, to the point where I now use it almost exclusively, usually from within Python.

With DuckDB, I believe we're moving towards a simpler world where most tabular data can be processed on a single large machine. The era of clusters is coming to an end for all but the largest datasets. [^1]

[^1]: [DuckDB Goes Distributed - DeepSeeks](https://mehdio.substack.com/p/duckdb-goes-distributed-deepseeks)

This post sets out some of my favourite features of DuckDB that set it apart from other SQL-based tools.  An  <Link to ="/recommend_sql/">earlier post</Link> explains why I favour SQL.   In a nutshell, it's simple to manage, ergonomic, fast, and more fully featured than other SQL-based tools.



In a nutshell, its killer features are:
- Speed.  DuckDB on a single node is sufficient for all but the largest datasets.
- Simple to install - extremely easy and use to install anywhere.  This makes it ideal for use in Github Actions or other CI.
- Suppo

## Speed

DuckDB consistently benchmarks as one of the fastest data processing engines.  The benchmarks I've seen show there's not much in it between the leading open source engines - which at the moment seem to be polars, duckdb and datafusion.

## Simple to install, no dependencies.

