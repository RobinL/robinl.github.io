---
title: "Address Matching"
post_date: "2025-06-13"
post_category: "data"
description: ""
code_url: "https://github.com/RobinL/robinl.github.io/blob/dev/src/mdx/address_matching.mdx"
prob_linkage_category: "address_matching"
tutorial_number: 1
date: "2025-06-13"
---

export { MDXLayout as default } from '../components/MDXLayout';
import { SEO } from "../components/SEO"
import Subtitle from "../components/Subtitle.jsx"
import { Link } from "gatsby"



export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;

# Building Accurate Address Matching Systems

<Subtitle>Feature engineering tricks to improve matching accuracy</Subtitle>

Address matching (geocoding) is a notoriously difficult problem due to the unpredictable characteristics of addresses.[^1].

Consider the example the following two matching addresses:

- 23A Marchant House, Jubilee Street, London, LO1 23D
- Flat A, Top Floor, Marchant House, 23 Jubilee Street, Fulham, LO1 23D

The above addresses exhibit far more variation than the following two non-matching addresses:

- Flat A 24 Jubilee Street, London, LO1 23D
- Flat A 25 Jubilee Street, London, LO1 23D

One of the most common record linkage approaches - known as the Fellegi-Sunter model - is not well suited to address matching because:
- there is correlation between different parts of an address, violating the statistical assumptions of the Fellegi-Sunter model
- the same address can be represented in multiple different ways, and it it almost impossible to parse any arbitrary address into a standardised/canonical form

To get the best accuracy in record linkage, we need a model that uses as much information from the input data as possible.

In this post, I share some tricks and techniques we can use to exploit the information in addresses as much as possible to maximise accuracy.  These tricks are used in my work-in-progress free and open source address matching library, [`uk_address_matcher`](https://github.com/RobinL/uk_address_matcher).

## High level ideas

In an ideal world, we'd use something like libpostal to parse addresses into a canonical form - e.g. splitting out flat number, house number, street name and so on.

In my experience, this approach suffers a fatal flaw: the hardest addresses to match are also the hardest to parse, because inherent ambiguities mean they can't be parsed reliably (consistently) into canonical form.  As a result:
- We can reliably parse the easy addresses, but it's straightforward to match those without sophisticated parsing approaches
- We can't reliably parse the hard addresses, so it doesn't help us to match where it's most needed.


## Blocking stage

The purpose of blocking is to recover a list of candidate matches which will be put through the scoring.  The aim of the blocking stage is to have high recall (i.e. not to miss the true match).  Precision is less important, because we will be scoring the candidates to find the true match at the next stage.

A simple blocking strategy could be to simply find all addresses in the postcode of the query address.  This is a good start, but in practice suffers two flaws:
- The list of candidates can be excessively long, resulting in slower performance
- The query address may not have a postcode, or the postcode may be incorrect

Further blocking strategies are more tricky because of the unpredictable nature of addresses.  In particular, since we can't reliably parse the addresses into a canonical form, simply blocking techniques such as 'street name plus number' are not reliable.

The following blocking tricks can help - and are best used in combination to maximise recall whilst maintaining a managable list of candidates.

### n-grams combined with term frequencies

We can pre-processes addresses to extract n-grams and their associated term frequencies (frequency of occurrence across the corpus of all addresses).   This allows us to identify which tokens are uncommon enough to be useful for blocking (i.e. will restrict the number of candidates to a manageable number).

Many strategies are possible here, but a simple approach could be to identify the least common bigram or trigram in each address, and to block on that (after filtering out any excessively common bigrams).

### Numerics plus postcode















## Scoring stage












[^1]: See, for example, [Falsehoods Programmers Believe About Addresses](https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/)
