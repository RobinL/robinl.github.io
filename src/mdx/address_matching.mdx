---
title: "Building Accurate Address Matching Systems"
post_date: "2025-06-13"
post_category: "data"
description: ""
code_url: "https://github.com/RobinL/robinl.github.io/blob/dev/src/mdx/address_matching.mdx"
prob_linkage_category: "address_matching"
tutorial_number: 1
date: "2025-06-13"
---

export { MDXLayout as default } from '../components/MDXLayout';
import { SEO } from "../components/SEO"
import Subtitle from "../components/Subtitle.jsx"
import { Link } from "gatsby"
import AddressComparison from "./address_matching/AddressComparison.jsx"



export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;

# Building Accurate Address Matching Systems

<Subtitle>Feature engineering tricks to improve the accuracy of geocoding</Subtitle>


## The challenge


Address matching (geocoding) is a notoriously difficult problem due to unpredictable structure of addresses and the many different ways an address can be written.


Substantial variation can exist between two matching addresses - for instance:


<AddressComparison
  addressA="Flat 165 Block 3 Philpot Square, Hammersmith And Fulham"
  addressB="165, Philpot Square, London"
  isMatch={true}
/>

Whereas the following example has far less variation, but does not match:

<AddressComparison
  addressA="Flat A 24 Jubilee Street, London, LO1 23D"
  addressB="Flat A 25 Jubilee Street, London, LO1 23D"
  isMatch={false}
/>

Unfortunately one of the most effective general record linkage approaches – known as the <Link to="/intro_to_probabilistic_linkage/">Fellegi-Sunter model</Link> – is not well suited to address matching because:
- there is correlation between different parts of an address, violating model's statistical assumptions
- the model assumes input data is consistently split across multiple columns (e.g. first name, surname, DoB etc.), but address data often comes as a single string, and reliably parsing this into a set of standardised columns is very difficult

## Structuring the problem

To maximise accuracy, we need a model that 'wrings' as much information out of the input data as possible.

In this post, I share some tricks and techniques we can use to exploit the information in addresses as much as possible to maximise accuracy.  Tangible implementations of tricks are used in my work-in-progress free and open source address matching library, [`uk_address_matcher`](https://github.com/RobinL/uk_address_matcher) and another promising library [`whereabouts`](https://github.com/ajl2718/whereabouts).



## High level approach

In an ideal world, we'd use something like  [libpostal](https://github.com/openvenues/libpostal) or a [Conditional Random Fields](https://www.ons.gov.uk/methodology/methodologicalpublications/generalmethodology/onsworkingpaperseries/onsworkingpaperseriesno17usingdatasciencefortheaddressmatchingservice) model to _reliably_ parse addresses into a canonical form - e.g. splitting out flat number, house number, street name and so on.

In practice, this approach suffers from a paradox: the hardest addresses to match are also the hardest to parse, because the harder addresses contain ambiguities that they can't be parsed reliably (consistently) into canonical form.  As a result:
- We can reliably parse the easy addresses, but it's straightforward to match those without sophisticated parsing approaches
- We can't reliably parse the hard addresses, so it doesn't help us to match where it's most needed.

The `Philpot Square` addresses shown above is a good practical example: what field should the `165` go in from `165, Philpot Square, London`?  In some sense, solving this problem amounts to figuring out what the true address is - so we have a circular problem.


## Blocking stage

The purpose of blocking is to recover a list of candidate matches which will be put through the scoring.  The aim of the blocking stage is to have high recall (i.e. not to miss the true match).  Precision is less important, because we will be scoring the candidates to find the true match at the next stage.

A simple blocking strategy could be to simply find all addresses in the postcode of the query address.  This is a good start, but in practice suffers two flaws:
- The list of candidates can be excessively long, resulting in slower performance
- The query address may not have a postcode, or the postcode may be incorrect

Further blocking strategies are more tricky because of the unpredictable nature of addresses.  In particular, since we can't reliably parse the addresses into a canonical form, simply blocking techniques such as 'street name plus number' are not reliable.

The following blocking tricks can help - and are best used in combination to maximise recall whilst maintaining a managable list of candidates.

### n-grams combined with term frequencies

We can pre-processes addresses to extract n-grams and their associated term frequencies (frequency of occurrence across the corpus of all addresses).   This allows us to identify which tokens are uncommon enough to be useful for blocking (i.e. will restrict the number of candidates to a manageable number).

Many strategies are possible here, but a simple approach could be to identify the least common bigram or trigram in each address, and to block on that (after filtering out any excessively common bigrams).

### Numerics plus postcode















## Scoring stage


## Further reading

- A variety of interesting edge casees can be found in [Falsehoods Programmers Believe About Addresses](https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/)


### Some examples of different ways to represent the same address

- Maisonette First And Second Floors, 14, Hadyn Park Road,
- Top Floor Flat 14 Hadyn Park Road, London





<AddressComparison
  addressA="23A Marchant House, Jubilee Street, London, LO1 23D"
  addressB="Flat A, Top Floor, Marchant House, 23 Jubilee Street, Fulham, LO1 23D"
  isMatch={true}
/>