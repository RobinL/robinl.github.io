---
title: "An Interactive Introduction to Record Linkage (Data Deduplication)"
description: "A set of interactive, explorable explanations of the Fellegi Sunter model, providing an introduction to probabilistic record linkage (data deduplication)."
post_date: "2021-05-20"
post_category: "probabilistic_linkage"
code_url: "https://observablehq.com/@robinl/d51533bbe054b3d8"
prob_linkage_category: "tutorial"
tutorial_number: 1
post_latest_update: "2023-09-12"
---

export { MDXLayout as default } from '../components/MDXLayout';
import { SEO } from "../components/SEO"
import { prior } from "../components/Definitions";

export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;


import notebook from '@robinl/d51533bbe054b3d8';

import {ObservableCell, WithObservableProvider}   from '../components/ObservableCells';

import TutorialNav from '../components/TutorialNav';
import CompactTutorialNav from '../components/CompactTutorialNav';

<CompactTutorialNav frontmatter={props.pageContext.frontmatter} />

# An Interactive Introduction to Probabilistic Record Linkage (Data Deduplication)

## Aims

This is part one of a series of interactive articles that aim to provide an introduction to the theory probabilistic record linkage (data deduplication).

In this article I provide a high-level description of the purpose of probabilistic record linkage, and an interactive example of a simple Fellegi-Sunter model.

Subsequent articles explore the theory in more details.

These materials align closely to the probabilisic model used by [Splink](http://github.com/moj-analytical-services/splink), a piece of open source software for record linkage at scale.

These articles cover the theory only.  For a guide on how to build record linkage models in practice using Splink, see [here](https://moj-analytical-services.github.io/splink/demos/tutorials/00_Tutorial_Introduction.html)

## What is probabilistic record linkage?

Probablistic record linkage is a technique used to link together records that lack unique identifiers.

In the absence of a unique identifier such as a National Insurance number, we can use a combination of individually non-unique variables such as name, gender and date of birth to identify individuals.

Record linkage can be done within datasets (deduplication), between datasets (linkage), or both.

Linkage is 'probabilistic' in the sense that it relies on the balance on evidence. For instance, in a large dataset, observing that two records match on the full name `John Smith` provides some evidence that these two records may refer to the same person, but this evidence is inconclusive because it's possible there are two different `John Smith`s.

More broadly, it is often impossible to classify pairs of records as matches or non-matches beyond any doubt. Instead, the aim of probabilisitic record linkage is to quantify the probability that a pair of records refer to the same entity by considering evidence in favour and against a match and weighting it appropriately.

The most common type of probabilistic record linkage model is called the Fellegi-Sunter model.

We start with a {prior}, which represents the probability that two records drawn at random are a match. We then compare the two records, increasing the match probability where information in the record matches, and decreasing it when information differs.

The amount we increse and decrease the match probability is determined by the 'partial match weights' of the model.

For example, a match on postcode gives us more evidence in favour of a match on gender, since the later is much more likely to occur by chance.

The final prediction is a simple calculation:  we sum up partial match weights to compute a final match weight, which is then converted into a probability.

## Simple example

Let's take a look at at an example of a simple Fellegi-Sunter model to calculate match probability interactively. This model will compare the two records in the table, and assess whether they refer to the same person, or different people. <mark>You may edit the values in the table to see how the match probability changes.</mark>


<WithObservableProvider notebook={notebook}>
    <ObservableCell cellName="table" />
    <ObservableCell cellName="estimated_probability" />

    We can represent the model graphically using a waterfall chart, which is read left to right. We start with the prior, and take each column into account in turn, with different match weights being applied to each column. You can hover over the bars to see how the probability changes as each subsequent field is taken into account.

    <ObservableCell cellName="viewof show_complex" />
    <ObservableCell cellName="waterfall_chart" />
   Columns with higher number of distinct values, such as date of birth, tend to represent stronger evidence in favour of a match since it's less likely that two records chosen at random would match by coincidence.

    Where a column does not match, this is usually evidence against a match. However, the evidence may not be strong - for example, people move house, which could cause a mismatch on the 'postcode' column.



</WithObservableProvider>

<TutorialNav frontmatter={props.pageContext.frontmatter} />




