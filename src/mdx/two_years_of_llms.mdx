---
title: "The emerging impact of LLMs"
post_date: "2024-10-23"
post_category: "data"
description: "What will be the impact of LLMs on knowledge workers"
code_url: "https://github.com/RobinL/robinl.github.io/blob/dev/src/mdx/llm_short_term_thoughts_questions.mdx"
---

export { MDXLayout as default } from '../components/MDXLayout';
import { SEO } from "../components/SEO"
import Subtitle from "../components/Subtitle.jsx"
import { Link } from "gatsby"

export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;

# The emerging impact of LLMs on productitivity

As an <Link to="../llm_short_term_thoughts_questions"> intensive user</Link> of LLMs, this post contains current thoughts on the impact of LLMs: where and how they're being used to most effect, and future trends.

### Knowlege workers will increasingly intermediate information through LLMs, rather than directly reading it

This pattern is emerging in multiple applications, and I find it genuinely useful.  For example, Office 365 Copilot and Apple Intelligence are starting to summarise emails.  ChatGPT Search and [Perplexity](https://www.perplexity.ai/) intermediate between web pages and the reader.  Custom GPTs and Claude Projects both allow you to chat with a knowledgebase. In the year since I last <Link to="../llm_short_term_thoughts_questions">mentioned it</Link>, it feels like this has gone from a likely future development to real, working tech that's well on the path to being widespread.

In the short term, a straightforward extensions of this which is already emerging is that team and corporate knowledge bases will be accessed thought a chat interface.  I'm starting to wish that all the teams I work in had a person curating the team knowledge into context for an LLM to give me easier access. I have done this for my work work [here](https://moj-analytical-services.github.io/splink/topic_guides/llms/prompting_llms.html).  A year ago, this did not work well at all.  Now it's pretty good - due to a combination of longer context models and improvements in RAG implementations.  In the longer term, I imagine this will largely be automated, and the knowledebase will be able to include pretty much all team communications - Slack, emails, video calls, presentations and so on.

### LLMs' coding abilities will improve faster than general abilities

Over the past year there has been dramatic progress in the utility of LLMs to software developers, both in terms of the qualtity of models, and their integration with programming tools (e.g. [Cursor](https://www.cursor.com/) with Sonnet 3.5).

Whether [scaling is over](https://futurism.com/the-byte/openai-diminishing-returns) or not, it's likely LLMs' coding ability will improve faster than general abilities, since there's a [close feedback loop](https://lexfridman.com/cursor-team-transcript/#chapter17_synthetic_data). In addition, the models themselves help developers quickly integrate them into programming tools, enabling a virtuous cycle of improvement.

I see this trend continuing.  Increasingly the skill of software development will be mostly the ability to precisely describe the desired functionality, and to arbiter the quality of code outputted by the LLM and iteratively improve it. This has always been the hard part of software development, so the impact is more limited than it first appears, but it does lead to significantly increased pace of delivery and smaller teams.

One key benefit is that working prototypes are much quicker, so mapping out the space of ideas, and iteratively improving is much faster.

### LLMs for education will deliver the ed-tech dream that's always been promised

Since I was in school over 20 years ago, software has always promised to radically improve education and underdelivered.  I think that's now changing.

Even in its current state, Open AI's Advanced Voice Mode often explains things better than I can to my 6 year old.  Sure, it makes mistakes, but so do I.

It seems likely these capabilities will develop in multiple dimensions, resulting in an expert personal tutor for all children:

- LLMs need to develop better long term memories of past conversations. Closely related, models need to be customised to be aware of curriculums and prerequisite knowledge.
- Advanced Voice Mode needs web search capabilities (or the ability to work with a knowledgebase)
- Models need to improve their multimodal capabilities - the ability to output diagrams and graphics in particular.

I'm optimistic about this because these feel like iterative improvements on existing tech rather than requireing new breakthroughts.

To be clear, from my experience using these tools with my kids, I don't think this eliminates the need for teachers. I do think it empower teachers to be much more effective.  As with most other uses of LLMs, it requires practice and effort to learn how to use them well, and the way in which teachers will use them are probably personal to their style.

### Where's more value likely to emerge be soon?

It's impossible to predict just how good LLMs will get, but I'm particularly excited about the possibility of more agentic behaviour and computer use - a few examples:

- Agentic behavior in code editors - e.g. the ability to run a debugger to iteratively detect and fix problems
- Effective computer use - e.g. filling out a PDF forms, doing annoying jobs like filling out and expenses sheet
- LLMs will begin to write PRs in response to Github issues.




