---
title: "Two Years of LLMs: Current Thoughts"
post_date: "2024-10-23"
post_category: "data"
description: "What will be the impact of LLMs on knowledge workers"
code_url: "https://github.com/RobinL/robinl.github.io/blob/dev/src/mdx/llm_short_term_thoughts_questions.mdx"
---

export { MDXLayout as default } from '../components/MDXLayout';
import { SEO } from "../components/SEO"
import Subtitle from "../components/Subtitle.jsx"
import { Link } from "gatsby"

export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;

# Further thoughts on the short term impact of LLMs

I've been usng LLMs intensely for two years now.  This post contains my current thoughts about their impact, around a year on from my <Link to="../llm_short_term_thoughts_questions"> previous post</Link>.

### Knowlege workers will increasingly intermediate information through LLMs, rather than directly reading it

This pattern is emerging in multiple applications, and I find it genuinely useful.  For example, Office 365 Copilot and Apple Intelligence are starting to summarise emails.  ChatGPT Search and [Perplexity](https://www.perplexity.ai/) intermediate between web pages and the reader.  Custom GPTs and Claude Projects both allow you to chat with a knowledgebase. In the year since I last <Link to="../llm_short_term_thoughts_questions">mentioned it</Link>, it feels like this has gone from a likely future development to real, working tech that's well on the path to being widespread.

In the short term, fairly straightforward extensions of this are likely to be team and corporate knowledge bases that are accessed thought a chat interface.  I'm starting to wish that all the teams I work in had a person curating the team knowledge into context for an LLM to give me easier access. I have done this for my work work [here](https://moj-analytical-services.github.io/splink/topic_guides/llms/prompting_llms.html).  A year ago, this did not work well at all.  Now it's pretty good - due to a combination of longer context models and improvements in RAG implementations.

### LLMs' coding abilities will improve faster than general abilities

Over the past year there has been dramatic progress in the utility of LLMs to software developers, both in terms of the qualtity of models, and their integration with programming tools (e.g. [Cursor](https://www.cursor.com/) with Sonnet 3.5).

Whether [scaling is over](https://futurism.com/the-byte/openai-diminishing-returns) or not, it's likely LLMs' coding ability will improve faster than general abilities, since there's a [close feedback loop](https://lexfridman.com/cursor-team-transcript/#chapter17_synthetic_data). The models themselves help developers quickly integrate them into programming tools, enabling a virtuous cycle of improvement.

I see this trend continuing.  Increasingly the skill of software development will be mostly the ability to precisely describe the desired functionality, and to arbiter the quality of code outputted by the LLM and iteratively improve it. This has always been the hard part of software development, so the impact is more limited than it first appears, but it does lead to significantly increased pace of delivery and smaller teams.

One key benefit is that working prototypes are much quicker, so mapping out the space of ideas, and iteratively improving is much faster.

- LLMs provide something of an all-purpose tool for knowledge workers.  Some killer 'universal applications' may emerge, but much of their value is in personalised, individual use cases that users tailor to their individual jobs and ways of working. As a result, it takes time and conscious effort for people to learn how to use them effectively.


### LLMs for education will deliver the ed-tech dream that's always been promised

Since I was in school over 20 years ago, software has always promised to radically improve education and underdelivered.  I think that's now changing.

Even in its current state, Open AI's Advanced Voice Mode often explains things better than I can to my 6 year old.  Sure, it makes mistakes, but so do I.

It seems likely these capabilities will develop in multiple dimensions, and the end result will be an expert personal tutor for all children:

- LLMs need to develop better long term memories of past conversations. Closely related, models need to be customised to be aware of curriculums and prerequisite knowledge.
- Advanced Voice Mode needs web search capabilities (or the ability to work with a knowledgebase)
- Models need to improve their multimodal capabilities - the ability to output diagrams and graphics in particular.

All of these seems like iterative improvements on echnisting tech rather than requireing new breakthroughts.

To be clear, from my experience using these tools with my kids, I don't think this eliminates the need for teachers. But I do think it empower teachers to be much more effective.

### Less certain capabilities




### Where's the value now?

-
- I think I'm about 50% more productive when working on programming tasks when using Cursor + Sonnet 3.5 vs. coding with no LLM

### Where's the value likely to be soon?

I think it's impossible to predict just how good LLMs will get, but the capabilities I think are very likely to emerge in the next two years are:


- Effective computer use - e.g. filling out a PDF form, putting in a request to the IT catalogue
- LLMs will begin to write PRs in response to Github issues.  Starting with small PRs to precisely described is
- The ability to hold whole codebases in context
- Agentic behavior in code editors



----
##

It remains fairly disorganised, but I've written thoughts in three themes:

- My personal real world uses of LLMs to enhance my productivity

## LLMs as tools for individuals vs. organisations

I feel like we're in a very peculiar time for LLMs.  Myself, and many people I speak to from a range of professions claim to be using them individually to significantly boost their productivity.  I estimate I'm about 50% more productive, but I accept that's at the high end, because computer programming is one of their key strengths.

But I'm yet to see many big, compelling organisational-level use cases where the productivity of a whole company is measurably affected.

Is that because LLMs are most helpful with practice?

Or that different people find them helpful in different ways, and so it's hard to use them to provide a one-size-fits-all solution that helps even people who aren't interested in them?

I'm not sure, but I feel a strong sense of cognative dissonance around my personal experience with them, and the number of people who either ignore them or are outright sceptical of their value.

### Some organisational use cases that seem likely to

- LLMs as semantic search and summary across internal documents

### Reflecting on a year ago

Last year I wrote:

>  [Quote about information being filtered through LLMs]

We're starting to see this 'at scale' in tools like Apple Intelligence, Office 365 Copilot and gmail.

### Some ways that LLMs may be used more effectively


People should start to curate knowledgebases of information specifically to be ingested by LLMs.  i.e. the canonical docs