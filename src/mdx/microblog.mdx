---
title: "Microblog"
post_date: "2025-01-16"
post_category: "quotes_links"
description: "My microblog"
code_url: "https://github.com/RobinL/robinl.github.io/blob/dev/src/mdx/microblog.mdx"
---

export { MDXLayout as default } from '../components/MDXLayout';
import { SEO } from "../components/SEO"
import Microblog from "../components/Microblog"
import { Link } from "gatsby"

export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;

# Microblog


<Microblog
    title="LLMs for government productivity"
    date="2025-02-13"
    tags={["llms", "government", "productivity"]}
>

I think the single most productivity-enhancing use of LLMs in government would be give all government devs and data scientists access to Cursor (or similar). I am not yet convinced of the widespread value of 'behind the scenes' use cases of LLMs, but very bullish on skilled human-in-the-loop applications, especially coding.

Undoubtably this situation will change as models improve, but at the moment there's usually not enough 9s of reliability to use in fully automated use cases.

</Microblog>

<Microblog
    title="LLMs getting better at coding"
    date="2025-02-05"
    tags={["llms", "coding", "ai"]}
>

[Latest Lex episode at 02:43:31](https://lexfridman.com/deepseek-dylan-patel-nathan-lambert-transcript/#:~:text=It%E2%80%99s%20even%20less%20prevalent) has a good section on why chain-of-thought matters over and above just 'it increases the benchmark results'

It hit me very similar to when I [first heard](https://youtu.be/U5OD8MjYnOM?si=J9rACnXmZH2HDC9R&t=6055) ([transcript](https://v1.transcript.lol/read/youtube/%40lexfridman/6522f348033150beacd16e2a?part=1#:~:text=And%20I%20think%20there%27s%20a%20lot%20of%20fundamental%20questions) ) the idea that code generation abilities would improve faster than natural language.  It feels like potentially chain-of-thought is the key to making this work.

These two Kapathy tweets also very relevant:
[tweet1](https://x.com/karpathy/status/1883941452738355376) [tweet2](https://x.com/karpathy/status/1885026028428681698)

Seems quite likely we'll see superhuman coding abilities in the not too distant future.

</Microblog>

<Microblog
    title="Using DuckDB in ChatGPT Code Interpreter"
    date="2025-01-28"
    tags={["duckdb", "chatgpt", "tips"]}
>
You can use DuckDB in ChatGPT's code interpreter by providing this specific wheel file:

`duckdb-1.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl`

from [here](https://pypi.org/project/duckdb/#files).

If you encounter any issues, you can copy paste the available wheels into ChatGPT and ask it to analyse which is the most likely to work.

For Altair, you need:
[narwhals-1.24.1-py3-none-any.whl](https://files.pythonhosted.org/packages/68/0e/882f7c0e073bf1f310dce159af6186826ca9b8ee7c170771c23e52a373dc/narwhals-1.24.1-py3-none-any.whl)
then
[altair-5.5.0-py3-none-any.whl](https://files.pythonhosted.org/packages/aa/f3/0b6ced594e51cc95d8c1fc1640d3623770d01e4969d29c0bd09945fafefa/altair-5.5.0-py3-none-any.whl)

Note: I could not get png generation to work because the `vl_convert_python` wheel would not install.
</Microblog>

<Microblog
    title="Using a uv shebang line"
    date="2025-01-28"
    tags={["python", "uv", "tips"]}
>
Rob Allen says:
> I create a fair few scripts in my ~/bin/ directory to automate tasks. Since discovering [uv and inline script metadata](https://akrabat.com/defining-python-dependencies-at-the-top-of-the-file/), I've started using Python far more for these.
>
>
> As `~/bin` is on my path, I want to run the script by calling it directly on the command line. To do this, I use this shebang:
>
> ```bash
> #!/usr/bin/env -S uv run --script
> ```
>


Full article [here](https://akrabat.com/using-uv-as-your-shebang-line/).
</Microblog>


<Microblog
    title="ClickHouse Obfuscator - Data Anonymization Tool"
    date="2025-01-16"
    tags={["clickhouse", "data", "privacy"]}
>
The [ClickHouse obfuscator](https://clickhouse.com/docs/en/operations/utilities/clickhouse-obfuscator) is a tool for anonymizing production data while preserving its key statistical properties. It maintains:

- Value cardinalities and distributions
- Data compression ratios
- String lengths and UTF-8 validity
- Time series continuity

See also [here](https://github.com/ClickHouse/ClickHouse/tree/master/programs/obfuscator)
</Microblog>


<Microblog
    title="National Data Library thoughts"
    date="2025-01-16"
    tags={["data", "governance", "AI"]}
>
Three key priorities for building a National Data Library:

1. Data sharing and governance must come first - before any technical solutions. Success depends on data owners being convinced the NDL will make their lives easier, not harder.

2. Access permissions and management systems need to be rock-solid before building analytical capabilities. Get the foundations right.

3. Design for an AI-first future - by the time the NDL is delivered, most analysis will likely be AI-assisted. The architecture needs to anticipate this.
</Microblog>

<Microblog
    title="Understanding DuckDB Connection Types in Python"
    date="2024-01-16"
    tags={["python", "duckdb", "database"]}
>
DuckDB offers special connection types in Python:

- `:memory:name` - Creates/connects to a named in-memory database that can be shared across connections
- `:default:` - Uses the default connection stored in the DuckDB module

Example:
```python
import duckdb

# Create table in default connection
duckdb.execute("CREATE TABLE tbl AS SELECT 42 as value")

# Access same table through explicit default connection
con = duckdb.connect(":default:")
con.sql("SELECT * FROM tbl")  # Works!

# Shared named memory connection
con3 = duckdb.connect(":memory:shared_db")
con4 = duckdb.connect(":memory:shared_db")  # Same database as con3
```

See docs [here](https://duckdb.org/docs/api/python/dbapi.html)
</Microblog>

<Microblog
    title="Configuring Python Path Visibility in VS Code interactive window (Jupyter)"
    date="2025-01-16"
    tags={["vscode", "jupyter", "tips"]}
>
When working with Jupyter notebooks in VS Code, add these settings to your `.vscode/settings.json`:
```json
{
    "jupyter.notebookFileRoot": "${workspaceFolder}",
    "python.analysis.extraPaths": [
        "${workspaceFolder}"
    ]
}
```

Now, the interactive window will run any script as if it's running from the root directory even if it's nested
</Microblog>


<Microblog
    title="An early email I sent on LLMs"
    date="2023-04-16"
    tags={["llms", "ai"]}
>

The following is an extract from an email I sent in April 2023 - of interest because it feels like this situation hasn't changed dramatically in the intervening 2 years.

--

No doubt you've seen some of the media coverage around new AI models, especially OpenAI GPT models, and have been thinking about how to use them with your teams.

I've been using them quite extensively, and the more I use them, the more impressed I am - i.e. I'm pretty sure this is not just a fad, but is a serious technological breakthrough that has the potential to revolutionise quite significant parts of Civil Service work.

I thought i may be useful to useful to note a handful of the areas where it feels like there is low hanging fruit where the models may be appropriate for serious applications:

1. Zero shot labelling.  This is an ability to take an input document and categorise it according to any criterion of your choice without training a new AI model (that's the 'zero shot' bit).  For example, taking a sentencing transcript as an input and the model categorising whether there was 'use of a weapon'.  The important technical advance here is that these new models understand semantics, not just keywords, so the transcript could contain 'the victim was stabbed', and the computer would recognise this as use of a weapon.

2. Semantic search across a large corpus of potentially unstructured documents.  There's an example here of using these models to analyse 1000 pages pdfs of Tesla's annual reports: https://twitter.com/mayowaoshin/status/1640385062708424708

Both (1) and (2) have been 'somewhat' possible in the past, but have been lots of work and haven't worked that well.  What's new is that these are now much easier and more accurate.

3. Code completion.  As a data scientist, I'm getting ChatGPT 4 to write probably 50%+ of my code.  So at the very least these models are a huge productivity amplifier to data scientists.

The biggest challenge is around data sharing and using these tools with sensitive government data.  It feels like getting a head start on understanding these legal issues may be an important first step.

</Microblog>
