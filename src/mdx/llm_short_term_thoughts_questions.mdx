---
title: "Thoughts and questions about the short term impact of LLMs on knowledge workers"
post_date: "2023-10-19"
post_category: "data"
description: "What will be the impact of LLMs on knowledge workers"
code_url: "https://github.com/RobinL/robinl.github.io/blob/dev/src/mdx/llm_short_term_thoughts_questions.mdx"
---

export { MDXLayout as default } from '../components/MDXLayout';
import { SEO } from "../components/SEO"
import {Subtitle} from "../components/Subtitle.jsx
import chart from "./llm_short_term_thoughts_questions/messages_words.json"

import { Vega, VegaLite } from "react-vega"

export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;

# Thoughts and questions about the short term impact of LLMs on knowledge workers

<Subtitle>Initial impressions of LLMs after about 10 months of use, 1,300 conversations, and 250,000 words of prompting</Subtitle>

This post contains some fairly disorganised thoughts and questions on the short term (maybe 0 - 3 years)[^1] effects of LLMs on organisations that embrace them.

Many of these effects are already happening, but probably in the early stages of the S curve.

[^1]: I'm assuming in the 3 year time horizon, there will be significant increase in the context size for LLMs

## Superficial increases in quality make it harder to filter out low-value content

Less effective staff will be able to easily produce superficially impressive work devoid of genuinely useful content.  Think: fancy consultancy-style Powerpoints.

Attention of high performing staff will potentially be diverted/distracted because they will find it harder to distinguish which colleagues will be best to collaborate with.

<div class="bg-gray-100 p-4 rounded-md shadow-sm">
  <strong>Question:</strong> Will the offensive or defensive capabilities of LLMs dominate here? Most content (especially from colleagues with weaker reputations) will be passed through an LLM summariser/de-jargoner before being read.
</div>

It could go in the other direction:  LLMs become so useful at summarisation and understanding the preferences of their users that much low value corporate information is neutralised.

## Impact on the most valuable skills

There will be a rebalancing of the most valuable 'core' skills of knowledge workers:

- Highly precise use of language will increase in importance.  Most obviously, the ability precisely to instruct an LLM.
- Substance will prevail over style since knowledge workers will use LLMs defensively to filter out jargon and other corporate nonsense.
- Reputation will be as important as ever, but possibly in-person contact will become even more important to developing a reputation
- Assembling the relevant information to a decision will become relatively more important, and the ability to summarise it less so, since managers will often 'chat' with the information rather than want to read a hand-crafted report.
- Pulling out a few key insights that managers _should_ want to know will still be important since LLMs will not have the full context for the decision.
- Tasks involving lots of 'boilerplate' (whether coding or correspondence) will be largely automated, meaning fewer people can get more done.
- Information will become even easier to retrieve, so memory will be less important than the ability to join up ideas

These are not dramatic changes, since most of these skills are already important to highly effective knowledge workers.  But they will further leverage productivity differentials.

<div class="bg-gray-100 p-4 rounded-md shadow-sm">
  <strong>Question:</strong> To what extent will LLMs disrupt the ability to be successful based on excessive use of jargon/buzzwords and dressing up ideas, as opposed to communicating in plain English and letting the clarity of thinking and quality of ideas do the work
</div>

I'm already using LLMs to filter out clickbait from the internet - surely the same will be possible in the workplace.

## Impact on recruitment

The effort required by a candidate to create to write a superficially impressive job application, highly tailored to the job description and company will be very low.

As a result, the strength of the signal in job applications will be significantly reduced making sifting much harder. More will have to rest on the interview, which are pretty noisy signals.

<div class="bg-gray-100 p-4 rounded-md shadow-sm">
  <strong>Question:</strong> Will a fundamental change in recruitment process be necessary? Perhaps a greater emphasis on probationary periods?
</div>

Reputation may become even more important.

## Impact on training

Classroom-based training for most generic skills will die out, except for where there's an ulterior purpose (e.g. networking).  Skills will be learned more on the job, with teaching delivered 'just in time' by the LLM.

With a highly effective personal tutor for everyone, motivation and enthusiasm to learn will become even more important.  The skill of learning new things quickly will become even more important.

## Impact on programmers

Superficial knowledge of programming languages will decline in value to zero, but very deep knowledge of languages and the principles of programming will still be important.

More junior staff will still be useful, but tenacity will increase in importance (the ability to solve the problem the LLM couldn't, which by definition will be the tricky ones.)

Clarity of vision and objectives and design of 'architecture' (how everything fits together) will become even more important.

Productivity will dramatically increase - particularly amongst the most motivated.

The design of software will change.  Developers will target building software that is described precisely enough that most people can use it via an LLM (i.e. the LLM can write the code by holding the library in context and thereby understanding how it should be used.)

## Endnote

This post was not written by an LLM, I promise!  However, I did use ChatGPT advanced data analysis to pull the following stats:

- I've been using ChatGPT since since 10 Dec 2022, during which time I've had 1,298 conversations.
- I've been using ChatGPT Plus (ChatGPT4) since 26th March 20203
- I have written a total of 246,000 words in 5,253 messages to ChatGPT

I've also used Claude (for its longer context) and Bing chat a bit, and prior to that the earliest reference I can find to using LLMs was Eleuther AI's 6b model in June 2021.

Here are my stats from ChatGPT.  (This data analysis was done by ChatGPT data analysis).

<VegaLite spec={chart} />
