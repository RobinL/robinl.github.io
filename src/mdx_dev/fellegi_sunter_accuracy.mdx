---
title: "Why Probabilistic Linkage is More Accurate than Fuzzy matching or TF-IDF alone"
description: "How to ensure that all available information is used to make predictions"
post_date: "2023-10-12"
post_category: "probabilistic_linkage"
code_url: "https://observablehq.com/@robinl/d51533bbe054b3d8"
prob_linkage_category: "tutorial"
tutorial_number: 6
---


export { ProbLinkageLayout as default} from '../components/ProbLinkageLayout'

import { SEO } from "../components/SEO"
import Subtitle from "../components/Subtitle.jsx"
import DefinitionToolTip from "../components/DefinitionToolTip";

export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;


# Why Probabilistic Linkage is More Accurate than Fuzzy matching or TF-IDF alone

<Subtitle>How effectively do different approaches to record matching use information in the records to make predictions?</Subtitle>

To get the best accuracy in record linkage, we want a model that uses as much information from the input data as possible.

This article describes three types of information that are most important, and how they are all leveraged by the Fellegi-Sunter model used by [Splink](https://github.com/moj-analytical-services/splink).

It also describes how some alternative record linkage approaches throw away some of this information, leaving accuracy on the table.

## The three types of information

Broadly, there are three categories of information that are relevant when trying to predict whether a pair of records match:

1. Similarity of the pair of records at and
2. Frequency of different values in the overall dataset
3. Data quality of the overall dataset

Let's look at each in turn.

I will use the following example records to help explain the categories:

| First Name | Last Name | Company Name          | Age | Phone Number  |
|------------|-----------|-----------------------|-----|---------------|
| John       | Hammond   | Flextronic Computers Plc| 35 | 0800 123456   |
| John        | Hamond   | Flextronic Computers Ltd| 34 | 07505 302010  |



######123
Notes:
The ciritical thing about fuzzy matching is the arbitraryness of the weights

Another flaw is it can't distinguish between the same distance on two different terms (John, Robin)

You could theoretically:
- Properly downweight no matches
- Give correct weight to average cardinality

But that's all arbitrary

## Similarity of the pairwise record comparison

The most obvious way to predict whether these records represent the same entity is to look whether the information in the columns is the same e.g. the first names are equal.

We also should check whether the information is similar because of the possibility of data entry - for example, `Hammond` vs `Hamond` may be an accident. Some types of information also change through time - which could explain the discrepancy in age.

Similarity can be measured quantitatively using fuzzy matching functions like Levenshtein or Jaro-Winker for text, or numeric differences.

These measures could be assigned different weights, and summed together to compute a total penalty.  If the total exceeded some threshold, the match would be rejected.

However, whilst this information is fundamental to effectively scoring record comparisons, it not sufficient to produce the best predictions.

The reason is that it doesn't take into account the broader context of the dataset: the 'cardinaltiy' (term freqncies).  This approach would therefore score the following two comparisons the same:

-  `John` vs `John`
- `Myra` vs `Myra`

when the later is much stronger evidence in favour of a match than the former.

It also doesn't take into account the context of errors.

The phone number




A simple algorithm would be to compute

- Similarity of the columns in the two records.  Are they an exact match, or do they fuzzy match?
- **The cardinality of the data**  How often are values like these observed in this dataset?  This information exists only _outside_ of the two records being immediately compared
- **Data quality** How common is it to see mistakes and variation in records like these.


Fuzzy matching functions that can detect the similarity between strings, but are unaware of the larger context of the dataset.  So ‘Pepsi’ and Pepsu’ have a jaro winkler score of 0.92.  But so do ‘Group’ and ‘Grouo’

An understanding of the cardinality of the field (number of distinct values), and the likelihood of coincidences occurring.  An exact match on the token ‘Pepsi’ provides much stronger evidence in favour of a match than a match on ‘Group’.  Similarly a fuzzy match on Pepsi at 0.92 is much stronger evidence of a match than a fuzzy match on Group.  The relevant question  is ’how much of a coincidence would it be to observed to different companies with a 0.92 match of ‘Group’ and ‘Grouo’ - and probabilistic models properly quantify this.

The strength of evidence against two record matching when fields do not match.  For example, if you observe ‘Pepsi Ltd’ vs ‘Pepsi PLC’, how much negative weight should we assign to the mismatch (Ltd vs PNC)  - how much evidence is this against these two records matching.

A lot of the power of probabilistic models comes from properly combining all three sources of information.  For large scale record linkage, it turns out that (2) and (3) are usually more powerful sources of accuracy that (1), particularly in the case you have multiple columns in your input dataset (e.g. if you have things in addition to the name, such as company address, directors names, turnover, legal structure, or anything else). (edited)

