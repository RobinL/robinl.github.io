---
title: "Probabilistic matching, fuzzy matching and TD-IDF"
description: "Interactive, explorable explanations of the Fellegi Sunter model, providing an introduction to probabilistic record linkage (data deduplication)."
post_date: "2023-10-12"
post_category: "probabilistic_linkage"
code_url: "https://observablehq.com/@robinl/d51533bbe054b3d8"
prob_linkage_category: "tutorial"
tutorial_number: 6
---


export { ProbLinkageLayout as default} from '../components/ProbLinkageLayout'

import { SEO } from "../components/SEO"
import Subtitle from "../components/Subtitle.jsx"
import DefinitionToolTip from "../components/DefinitionToolTip";

export const Head = ( props ) => <SEO frontmatter={props.pageContext.frontmatter} />;


# Why Probabilistic Linkage is More Accurate than Fuzzy matching or TF-IDF alone

<Subtitle>How effectively do different approaches to record matching use information in the records to make predictions?</Subtitle>

To get the best accuracy in record linkage, we want a model that uses as much information from the input data as possible.

This article describes the three main types of information that are important, and how they are all leveraged by the Fellegi-Sunter model used in [Splink](https://github.com/moj-analytical-services/splink).

It also describes  how some other record linkage approaches thrown away some of this information, leaving accuracy on the table.


## The three types of information

Broadly, there are three categories of information that are relevant when trying to predict whether a pair of records match:

1. Similarity of the two records at hand
2. Cardinality of different values in the overall dataset
3. Data quality of the overall dataset

Let's look at each in turn.

## Similarity of the records

- Similarity of the columns in the two records.  Are they an exact match, or do they fuzzy match?
- **The cardinality of the data**  How often are values like these observed in this dataset?  This information exists only _outside_ of the two records being immediately compared
- **Data quality** How common is it to see mistakes and variation in records like these.


Fuzzy matching functions that can detect the similarity between strings, but are unaware of the larger context of the dataset.  So ‘Pepsi’ and Pepsu’ have a jaro winkler score of 0.92.  But so do ‘Group’ and ‘Grouo’

An understanding of the cardinality of the field (number of distinct values), and the likelihood of coincidences occuring.  An exact match on the token ‘Pepsi’ provides much stronger evidence in favour of a match than a match on ‘Group’.  Similarly a fuzzy match on Pepsi at 0.92 is much stronger evidence of a match than a fuzzy match on Group.  The relevant question  is ’how much of a coincidence would it be to observed to different companies with a 0.92 match of ‘Group’ and ‘Grouo’ - and probabilistic models properly quantify this.

The strength of evidence against two record matching when fields do not match.  For example, if you observe ‘Pepsi Ltd’ vs ‘Pepsi PLC’, how much negative weight should we assign to the mismatch (Ltd vs PNC)  - how much evidence is this against these two records matching.

A lot of the power of probabilistic models comes from properly combining all three sources of information.  For large scale record linkage, it turns out that (2) and (3) are usually more powerful sources of accuracy that (1), particularly in the case you have multiple columns in your input dataset (e.g. if you have things in addition to the name, such as company address, directors names, turnover, legal structure, or anything else). (edited)

